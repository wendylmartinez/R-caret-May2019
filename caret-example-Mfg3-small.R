####################################################################
# Predicting industry output
# Example of caret for class, May 2019
#
# Objective:  Predict output measure for each of 21 industries for a year,
#  using data avaiable many months before the full data is available.
#  We'll compare the performance of different models and statistical methods.
#  The training data will be ALL years other than one, which is the test set.
#  Thus all observations are predicted based on out-of-sample information.
#  The accuracy criterion is the RMSE for all obsevations averaged together.

#########################################################################
# Section 0: setup
# Set working directory
setwd("C:/meyer/rdata/R-class-May2019")  # <== change this for your computer

rm(list=ls())  # workspace cleanup

# session options
options(echo=TRUE)
options(stringsAsFactors=FALSE)

# command line arguments
args <- commandArgs(trailingOnly=TRUE)

# external libraries
library(caret)   # this library does the training/test for OLS, ridge, lass, and enet

# Load data on industry output and predictors of output
Mfg3 = read.csv("Mfg3.csv")

# Make the industry code a factor variable
Mfg3$ind2 <- factor(Mfg3$ind2)

# Set up storage space for error metrics generated by various years and folds
errvec=integer(15)  # we'll use 7-14 of this for RMSEs from years 2007-2014
R2vec=integer(15)   # this will have R-squareds


#########################################################################
# Section 1:  Train caret OLS model on 7 years for one test year
TrainData <- subset(Mfg3, year != 2014) # The training set, used to set coefficients
TestData <- subset(Mfg3, year == 2014)  # The test set, for evaluating accuracy
  
# Train the model, setting parameters from test data set
lmtrained <- caret::train(prod ~ ipi+ppi+imports+exports+wages+emp+M3+ind2,
                            data = TrainData, method = "lm")

# examine some internals of the parameterized model
varImp(lmtrained)
summary(lmtrained)
lmtrained

# predict the growth in production by this industry based on parameterized model
predictions <- predict(lmtrained, newdata = TestData)
  
# record RMSE quality metric for this fold, that is, one reference year
RMSE2014 <- sqrt(mean((TestData$prod - predictions)^2))
Rsquared <- lmtrained$results$Rsquared

# display this cross-validated criterion of performance
cat("RMSE for OLS on 2014 with 7 growth predictors and 3 industry indicators: ",
    RMSE2014, "\n")



#########################################################################
# Section 2:  Model OLS7grow with "yearwise cross-validation"
# We'll predict every year, all industries using other 7 ind-years for training
# OLS with 7 growth predictors included plus broad industry indicators

for (yr in 7:14) {   # loop through 8 years, using every year for test
  TrainData <- subset(Mfg3, year != 2000+yr) # The training set, used to set coefficients
  TestData <- subset(Mfg3, year == 2000+yr)  # The test set, for evaluating accuracy

# Train the model, setting parameters from test data set
  lmtrained <- caret::train(prod ~ ipi+ppi+imports+exports+wages+emp+M3+ind2,
                                    data = TrainData, method = "lm")

# predict the growth in production by this industry based on parameterized model
  predictions <- predict(lmtrained, newdata = TestData)

# record RMSE quality metric for this fold, that is, one reference year
  errvec[yr] <- sqrt(mean((TestData$prod - predictions)^2))
}

RMSEoverall = mean(errvec[7:14])  # calc avg RMSE


# display this cross-validated criterion of performance
cat("RMSE for OLS with 7 growth predictors and 3 industry indicators: ",
         RMSEoverall, "\n")


#########################################################################
# Section 2: Model  OLS3grow
# OLS with IPI, PPI, and exports -- possbily the best model with three growth predictors
# and also industry indicators

for (yr in 7:14) {
  TrainData <- subset(Mfg3, year != 2000+yr) # The training set, used to set coefficients
  TestData <- subset(Mfg3, year == 2000+yr)  # The test set, for evaluating accuracy

# Train the model, setting parameters from test data set
  lmtrained <- caret::train(prod ~ ipi+ppi+exports+ind2,
                                    data = TrainData, method = "lm")

# predict the growth in production by this industry based on parameterized model
  predictions <- predict(lmtrained, newdata = TestData)

# record RMSE quality metric for this fold, that is, one reference year
  errvec[yr] <- sqrt(mean((TestData$prod - predictions)^2))
}

RMSEoverall = mean(errvec[7:14])  # calc avg RMSE

cat("RMSE for OLS with 3 growth predictors and 3 industry indicators: ",
        RMSEoverall, "\n")
# display this is the cross-validated criterion of performance



#########################################################################
# Section 3:  Train ridge model for one test year alone
TrainData <- subset(Mfg3, year != 2014) # The training set, used to set coefficients
TestData <- subset(Mfg3, year == 2014)  # The test set, for evaluating accuracy

# Train the model, setting parameters from test data set
trained <- caret::train(prod ~ ipi+ppi+imports+exports+wages+emp+M3+ind2,
                          data = TrainData, method = "ridge")

# examine some internals of the parameterized model
# . . . which now has a tuning parameter
varImp(trained)
summary(trained)
trained

# predict the growth in production by this industry based on parameterized model
predictions <- predict(trained, newdata = TestData)

# record RMSE quality metric for this fold, that is, one reference year
RMSE2014 <- sqrt(mean((TestData$prod - predictions)^2))
Rsquared <- trained$results$Rsquared

# display this cross-validated criterion of performance
cat("RMSE for ridge regression on 2014 with 7 growth predictors and 3 industry indicators: ",
    RMSE2014, "\n")


#########################################################################
# Section 4:  Ridge model with yearwise cross-validation
# OLS with 7 growth predictors included plus broad industry indicators

for (yr in 7:14) {
  TrainData <- subset(Mfg3, year != 2000+yr) # The training set, used to set coefficients
  TestData <- subset(Mfg3, year == 2000+yr)  # The test set, for evaluating accuracy

# Train the model, setting parameters from test data set
  lmtrained <- caret::train(prod ~ ipi+ppi+imports+exports+wages+emp+M3+ind2,
                                    data = TrainData, method = "ridge")

# predict the growth in production by this industry based on parameterized model
  predictions <- predict(lmtrained, newdata = TestData)

# record RMSE quality metric for this fold, that is, one reference year
  errvec[yr] <- sqrt(mean((TestData$prod - predictions)^2))
}

# average the RMSEs of the folds to get the overall RMSE
RMSEoverall = mean(errvec[7:14])  # calc avg RMSE

cat("RMSE for ridge regression with 7 growth predictors and 3 industry flags: ",
         RMSEoverall, "\n")
  # display this cross-validated criterion of performance



# You can replicate the above blocks for various other models
# replace "ridge" in section 4 by "lasso" or "enet" or "rf"
# some models will require some deeper change to this code or give errors
# Some models won't run without more years of data. 



cat("\nModels done.\n\n")
